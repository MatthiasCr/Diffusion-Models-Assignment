{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "982819e3",
   "metadata": {},
   "source": [
    "# Denoising Probabilistic Diffusion Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb411b7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install fiftyone wandb open-clip-torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a95276e",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1801efcf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from utils import UNet_utils, ddpm_utils\n",
    "\n",
    "# TODO: Initialize the U-Net model and load the pre-trained weights from notebook 05.\n",
    "\n",
    "# Make sure to use the same architecture as in the notebook.\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = UNet_utils.UNet(\n",
    "\n",
    "    T=400, img_ch=3, img_size=32, down_chs=(256, 256, 512), t_embed_dim=8, c_embed_dim=512\n",
    "\n",
    ").to(device)\n",
    "\n",
    "# model.load_state_dict(torch.load('path_to_your_model.pth')) # You need to provide the path to your trained model\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# TODO: Define a list of text prompts to generate images for.\n",
    "\n",
    "text_prompts = [\n",
    "\n",
    "    \"A photo of a red rose\",\n",
    "\n",
    "    \"A photo of a white daisy\",\n",
    "\n",
    "    \"A photo of a yellow sunflower\"\n",
    "\n",
    "]\n",
    "\n",
    "# --- Embedding Extraction using Hooks ---\n",
    "\n",
    "# We will use PyTorch hooks to extract the output of the 'down2' layer (the bottleneck).\n",
    "\n",
    "embeddings_storage = {}\n",
    "\n",
    "def get_embedding_hook(name):\n",
    "\n",
    "    def hook(model, input, output):\n",
    "\n",
    "        embeddings_storage[name] = output.detach()\n",
    "\n",
    "    return hook\n",
    "\n",
    "# TODO: Register a forward hook on the `down2` layer of the U-Net model.\n",
    "\n",
    "# The hook should store the output of the layer in the `embeddings_storage` dictionary.\n",
    "\n",
    "# model.down2.register_forward_hook(get_embedding_hook('down2'))\n",
    "\n",
    "\n",
    "# TODO: Modify the `sample_flowers` function from notebook 05 to generate images \n",
    "\n",
    "# and store the extracted embeddings.\n",
    "\n",
    "# You will need to run the generation process and then access the `embeddings_storage`\n",
    "\n",
    "# to get the embeddings for each generated image.\n",
    "\n",
    "# generated_images, _ = sample_flowers(text_prompts)\n",
    "\n",
    "# extracted_embeddings = embeddings_storage['down2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acbdde0",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4342be",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import open_clip\n",
    "\n",
    "# TODO: Calculate the CLIP score for each generated image against its prompt.\n",
    "\n",
    "# You can use the `calculate_clip_score` function from the evaluation guide.\n",
    "\n",
    "# TODO: Calculate the FID score for the set of generated images.\n",
    "\n",
    "# You will need the `calculate_fid` function and the Inception model from the evaluation guide.\n",
    "\n",
    "# You will also need to load the real TF-Flowers dataset to compare against."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b215c22e",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d32aa4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "import fiftyone.brain as fob\n",
    "\n",
    "# TODO: Create a new FiftyOne dataset.\n",
    "\n",
    "dataset = fo.Dataset(name=\"generated_flowers_with_embeddings\")\n",
    "\n",
    "# TODO: Iterate through your generated images and add them to the dataset.\n",
    "\n",
    "# For each image, create a fiftyone.Sample and add the following metadata:\n",
    "\n",
    "# - The file path to the saved image.\n",
    "\n",
    "# - The text prompt (as a `fo.Classification` label).\n",
    "\n",
    "# - The CLIP score (as a custom field).\n",
    "\n",
    "# - The extracted U-Net embedding (as a custom field).\n",
    "\n",
    "# TODO: Compute uniqueness for the dataset.\n",
    "\n",
    "# fob.compute_uniqueness(dataset)\n",
    "\n",
    "# TODO: Compute representativeness using the extracted U-Net embeddings.\n",
    "\n",
    "# fob.compute_representativeness(dataset, embeddings=\"unet_embedding\")\n",
    "\n",
    "# TODO: Launch the FiftyOne App to visualize your dataset and analyze the results.\n",
    "\n",
    "# session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fa239e",
   "metadata": {},
   "source": [
    "## Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08bc0e4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# TODO: Login to wandb.\n",
    "\n",
    "# wandb.login()\n",
    "\n",
    "# TODO: Initialize a new wandb run.\n",
    "\n",
    "# run = wandb.init(project=\"diffusion_model_assessment_v2\")\n",
    "\n",
    "# TODO: Log your hyperparameters (e.g., guidance weight `w`, number of steps `T`).\n",
    "\n",
    "# TODO: Log your evaluation metrics (CLIP Score and FID).\n",
    "\n",
    "# TODO: Create a wandb.Table to log your results. The table should include:\n",
    "\n",
    "# - The generated image.\n",
    "\n",
    "# - The text prompt.\n",
    "\n",
    "- The CLIP score.\n",
    "\n",
    "# - The uniqueness score.\n",
    "\n",
    "# - The representativeness score.\n",
    "\n",
    "# TODO: Finish the wandb run.\n",
    "\n",
    "# run.finish()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
